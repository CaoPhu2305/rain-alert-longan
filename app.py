import gradio as gr
import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
import requests
from io import BytesIO
from datetime import datetime, timedelta
import urllib3
import numpy as np
import os

# T·∫Øt c·∫£nh b√°o SSL
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ==========================================
# 1. C·∫§U H√åNH (D√†nh cho Model 2 L·ªõp)
# ==========================================
MODEL_PATH = 'best_model_binary_longan.pth' 

# Nh√£n cho b√†i to√°n nh·ªã ph√¢n (Binary)
CLASSES = ['‚úÖ An To√†n (M√¢y √çt/Kh√¥ng M∆∞a)', '‚ö†Ô∏è Nguy C∆° (M√¢y D√†y/M∆∞a)']

# Ch·∫°y tr√™n CPU ƒë·ªÉ ·ªïn ƒë·ªãnh tr√™n Hugging Face Free Tier
DEVICE = torch.device("cpu") 

# T·ªça ƒë·ªô Long An
LONG_AN_BBOX = "105.55,9.95,107.05,11.45"

# ==========================================
# 2. LOAD MODEL
# ==========================================
def load_model():
    print(f"‚è≥ ƒêang load model Binary t·ª´ {MODEL_PATH}...")
    try:
        # Kh·ªüi t·∫°o ResNet18
        model = models.resnet18(weights=None)
        num_ftrs = model.fc.in_features
        
        # C·∫•u tr√∫c l·ªõp cu·ªëi kh·ªõp v·ªõi l√∫c train (Dropout -> 2 L·ªõp)
        model.fc = nn.Sequential(
            nn.Dropout(p=0.5), # Dropout kh√¥ng ·∫£nh h∆∞·ªüng l√∫c eval, nh∆∞ng c·∫ßn ƒë·ªÉ kh·ªõp key
            nn.Linear(num_ftrs, 2) # QUAN TR·ªåNG: Output l√† 2
        )
        
        if os.path.exists(MODEL_PATH):
            state_dict = torch.load(MODEL_PATH, map_location=DEVICE)
            model.load_state_dict(state_dict)
            model.to(DEVICE)
            model.eval() # Ch·∫ø ƒë·ªô d·ª± b√°o
            print("‚úÖ Load model th√†nh c√¥ng!")
            return model
        else:
            print(f"‚ö†Ô∏è C·∫£nh b√°o: Kh√¥ng t√¨m th·∫•y file {MODEL_PATH}. H√£y upload file model l√™n Space.")
            return None
    except Exception as e:
        print(f"‚ùå L·ªói load model: {e}")
        return None

model = load_model()

# Transform ·∫£nh (Gi·ªëng h·ªát l√∫c train)
val_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# ==========================================
# 3. T·∫¢I ·∫¢NH V·ªÜ TINH (NASA API)
# ==========================================
def fetch_modis_image(date_obj, time_str):
    try:
        # Chuy·ªÉn gi·ªù VN sang UTC ƒë·ªÉ g·ªçi API
        full_dt_vn = datetime.combine(date_obj, datetime.strptime(time_str, "%H:%M").time())
        full_dt_utc = full_dt_vn - timedelta(hours=7)
        time_param = full_dt_utc.strftime("%Y-%m-%dT%H:%M:%SZ")

        url = "https://gibs.earthdata.nasa.gov/wms/epsg4326/best/wms.cgi"
        params = {
            "SERVICE": "WMS", "VERSION": "1.1.1", "REQUEST": "GetMap",
            "LAYERS": "MODIS_Aqua_CorrectedReflectance_TrueColor",
            "STYLES": "", "FORMAT": "image/jpeg", "SRS": "EPSG:4326",
            "BBOX": LONG_AN_BBOX, 
            "WIDTH": "512", "HEIGHT": "512",
            "TIME": time_param
        }

        print(f"üîó T·∫£i ·∫£nh Long An l√∫c: {time_param} UTC")
        response = requests.get(url, params=params, timeout=20, verify=False)
        
        if response.status_code == 200 and len(response.content) > 3000:
            img = Image.open(BytesIO(response.content))
            return img, "‚úÖ ƒê√£ t·∫£i ·∫£nh v·ªá tinh th√†nh c√¥ng."
        else:
            return None, "‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu ·∫£nh. (L·ªói th∆∞·ªùng g·∫∑p: V·ªá tinh ch∆∞a bay qua, ho·∫∑c tr·ªùi t·ªëi)."

    except Exception as e:
        return None, f"L·ªói k·∫øt n·ªëi: {str(e)}"

# ==========================================
# 4. H√ÄM D·ª∞ B√ÅO
# ==========================================
def predict_longan(day, month, year, time_input):
    if model is None: 
        return None, "‚ùå L·ªói: Ch∆∞a c√≥ file model (.pth) tr√™n Server!"
    
    # T·∫°o ƒë·ªëi t∆∞·ª£ng ng√†y t·ª´ 3 input ri√™ng bi·ªát
    try:
        date_input = datetime(int(year), int(month), int(day))
    except ValueError:
        return None, "‚ö†Ô∏è Ng√†y th√°ng nƒÉm kh√¥ng h·ª£p l·ªá!"

    # T·∫£i ·∫£nh
    img, msg = fetch_modis_image(date_input, time_input)
    if img is None: 
        return None, msg
    
    # D·ª± b√°o
    try:
        img_t = val_transform(img).unsqueeze(0).to(DEVICE)
        
        with torch.no_grad():
            outputs = model(img_t)
            probs = torch.nn.functional.softmax(outputs, dim=1)
            conf, idx = torch.max(probs, 1)
            
        label = CLASSES[idx.item()]
        
        # T·∫°o th√¥ng b√°o k·∫øt qu·∫£
        res_text = (
            f"üéØ K·∫æT QU·∫¢: {label}\n"
            f"üìä ƒê·ªô tin c·∫≠y: {conf.item()*100:.2f}%\n"
            f"üïí Th·ªùi gian: {day}/{month}/{year} - {time_input}"
        )
        return img, res_text
    except Exception as e:
        return img, f"L·ªói khi ch·∫°y model: {str(e)}"

# ==========================================
# 5. GIAO DI·ªÜN (3 INPUT NG√ÄY TH√ÅNG NƒÇM)
# ==========================================
valid_times = ["13:00", "13:10", "13:20", "13:30", "13:40", "13:50"]

# Kh√¥ng d√πng tham s·ªë theme/css ƒë·ªÉ tr√°nh l·ªói version
with gr.Blocks() as demo:
    # Ti√™u ƒë·ªÅ HTML cƒÉn gi·ªØa
    gr.Markdown(
        """
        <div style="text-align: center;">
            <h1>üõ∞Ô∏è H·ªÜ TH·ªêNG C·∫¢NH B√ÅO M∆ØA S·ªöM - T·ªàNH LONG AN</h1>
            <p>S·ª≠ d·ª•ng c√¥ng ngh·ªá Deep Learning (ResNet-18) ph√¢n t√≠ch ·∫£nh v·ªá tinh MODIS</p>
        </div>
        """
    )
    
    with gr.Row():
        # C·ªôt tr√°i: Nh·∫≠p li·ªáu
        with gr.Column():
            gr.Markdown("### 1Ô∏è‚É£ Ch·ªçn Th·ªùi Gian")
            
            # H√†ng ch·ª©a 3 √¥ nh·∫≠p: Ng√†y - Th√°ng - NƒÉm
            with gr.Row():
                inp_day = gr.Number(label="Ng√†y", value=datetime.now().day, precision=0, minimum=1, maximum=31)
                inp_month = gr.Number(label="Th√°ng", value=datetime.now().month, precision=0, minimum=1, maximum=12)
                inp_year = gr.Number(label="NƒÉm", value=datetime.now().year, precision=0, minimum=2000, maximum=2030)
            
            inp_time = gr.Dropdown(label="‚è∞ Gi·ªù V·ªá Tinh (Gi·ªù VN)", choices=valid_times, value="13:30")
            
            btn = gr.Button("üîç PH√ÇN T√çCH NGAY", variant="primary")
            
            gr.Markdown("‚ÑπÔ∏è *Khuy√™n d√πng khung gi·ªù **13:30** ƒë·ªÉ c√≥ ·∫£nh r√µ n√©t nh·∫•t.*")
        
        # C·ªôt ph·∫£i: K·∫øt qu·∫£
        with gr.Column():
            gr.Markdown("### 2Ô∏è‚É£ K·∫øt Qu·∫£ D·ª± B√°o")
            out_img = gr.Image(label="·∫¢nh V·ªá Tinh Th·ª±c T·∫ø", type="pil")
            out_txt = gr.Textbox(label="Chi Ti·∫øt", lines=4)
            
    btn.click(predict_longan, inputs=[inp_day, inp_month, inp_year, inp_time], outputs=[out_img, out_txt])
demo.launch()
